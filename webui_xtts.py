import os,shutil,sys,pdb,re
now_dir = os.getcwd()
sys.path.append(now_dir)
import json,yaml,warnings,torch
import platform
import psutil
import signal
from pathlib import Path

warnings.filterwarnings("ignore")
torch.manual_seed(233333)
tmp = os.path.join(now_dir, "TEMP")
os.makedirs(tmp, exist_ok=True)
os.environ["TEMP"] = tmp
if(os.path.exists(tmp)):
    for name in os.listdir(tmp):
        if(name=="jieba.cache"):continue
        path="%s/%s"%(tmp,name)
        delete=os.remove if os.path.isfile(path) else shutil.rmtree
        try:
            delete(path)
        except Exception as e:
            print(str(e))
            pass
import site
site_packages_roots = []
for path in site.getsitepackages():
    if "packages" in path:
        site_packages_roots.append(path)
if(site_packages_roots==[]):site_packages_roots=["%s/runtime/Lib/site-packages" % now_dir]
#os.environ["OPENBLAS_NUM_THREADS"] = "4"
os.environ["no_proxy"] = "localhost, 127.0.0.1, ::1"
os.environ["all_proxy"] = ""
for site_packages_root in site_packages_roots:
    if os.path.exists(site_packages_root):
        try:
            with open("%s/users.pth" % (site_packages_root), "w") as f:
                f.write(
                    "%s\n%s/tools\n%s/tools/damo_asr\n%s/GPT_SoVITS\n%s/tools/uvr5"
                    % (now_dir, now_dir, now_dir, now_dir, now_dir)
                )
            break
        except PermissionError:
            pass
from tools import my_utils
import traceback
import shutil
import pdb
import gradio as gr
from subprocess import Popen
import signal
from config import python_exec,infer_device,is_half,exp_root,webui_port_main,webui_port_infer_tts,webui_port_uvr5,webui_port_subfix,is_share
from tools.i18n.i18n import I18nAuto
i18n = I18nAuto()
from scipy.io import wavfile
from tools.my_utils import load_audio
from multiprocessing import cpu_count

import argparse
import os
import sys
import tempfile

import gradio as gr
import librosa.display
import numpy as np

import torch
import torchaudio
import traceback
from TTS.demos.xtts_ft_demo.utils.formatter import format_audio_list
from TTS.demos.xtts_ft_demo.utils.gpt_train import train_gpt

from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts

# from .list to .csv
import pandas as pd
from sklearn.model_selection import train_test_split

def split_csv(input_csv, train_csv, eval_csv, eval_size=0.15):
    # Load the data from the CSV file
    data = pd.read_csv(input_csv, delimiter='|', header=0)

    # Split the data into training and evaluation sets
    train_data, eval_data = train_test_split(data, test_size=eval_size, random_state=42)

    # Save the training data to a CSV file
    train_data.to_csv(train_csv, index=False, sep='|')

    # Save the evaluation data to a CSV file
    eval_data.to_csv(eval_csv, index=False, sep='|')

    print("CSV files have been successfully split.")


def convert_list_to_csv(input_file, output_file):
    try:
        # Open the input .list file to read
        with open(input_file, 'r', encoding='utf-8') as infile:
            # Open the output .csv file to write
            with open(output_file, 'w', encoding='utf-8') as outfile:
                # Write the header to the CSV
                outfile.write("audio_file|text|speaker_name\n")
                # Process each line in the input file
                for line in infile:
                    parts = line.strip().split('|')
                    if len(parts) == 4:
                        # Extract relevant parts: WAV file path and transcription
                        wav_path = parts[0]
                        transcription = parts[3]
                        # Write the formatted line to the CSV file
                        outfile.write(f"{wav_path}|{transcription}|coqui\n")
        print("Conversion to CSV completed successfully.")
        split_csv(output_file, "train.csv", "eval.csv")
        print("Split completed successfully")
        return "train.csv", "eval.csv"
    except Exception as e:
        print(f"An error occurred: {e}")


def clear_gpu_cache():
    # clear the GPU cache
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

XTTS_MODEL = None
def load_model(xtts_checkpoint, xtts_config, xtts_vocab):
    global XTTS_MODEL
    clear_gpu_cache()
    if not xtts_checkpoint or not xtts_config or not xtts_vocab:
        return "You need to run the previous steps or manually set the `XTTS checkpoint path`, `XTTS config path`, and `XTTS vocab path` fields !!"
    config = XttsConfig()
    config.load_json(xtts_config)
    XTTS_MODEL = Xtts.init_from_config(config)
    print("Loading XTTS model! ")
    XTTS_MODEL.load_checkpoint(config, checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab, use_deepspeed=False)
    if torch.cuda.is_available():
        XTTS_MODEL.cuda()

    print("Model Loaded!")
    return "Model Loaded!"

def run_tts(lang, tts_text, speaker_audio_file):
    if XTTS_MODEL is None or not speaker_audio_file:
        return "You need to run the previous step to load the model !!", None, None

    gpt_cond_latent, speaker_embedding = XTTS_MODEL.get_conditioning_latents(audio_path=speaker_audio_file, gpt_cond_len=XTTS_MODEL.config.gpt_cond_len, max_ref_length=XTTS_MODEL.config.max_ref_len, sound_norm_refs=XTTS_MODEL.config.sound_norm_refs)
    out = XTTS_MODEL.inference(
        text=tts_text,
        language=lang,
        gpt_cond_latent=gpt_cond_latent,
        speaker_embedding=speaker_embedding,
        temperature=XTTS_MODEL.config.temperature, # Add custom parameters here
        length_penalty=XTTS_MODEL.config.length_penalty,
        repetition_penalty=XTTS_MODEL.config.repetition_penalty,
        top_k=XTTS_MODEL.config.top_k,
        top_p=XTTS_MODEL.config.top_p,
    )

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as fp:
        out["wav"] = torch.tensor(out["wav"]).unsqueeze(0)
        out_path = fp.name
        torchaudio.save(out_path, out["wav"], 24000)

    return "Speech generated !", out_path, speaker_audio_file




# define a logger to redirect 
class Logger:
    def __init__(self, filename="log.out"):
        self.log_file = filename
        self.terminal = sys.stdout
        self.log = open(self.log_file, "w")

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()
        self.log.flush()

    def isatty(self):
        return False

# redirect stdout and stderr to a file
sys.stdout = Logger()
sys.stderr = sys.stdout


# logging.basicConfig(stream=sys.stdout, level=logging.INFO)
import logging
logging.basicConfig(
    level=logging.WARNING,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

def read_logs():
    sys.stdout.flush()
    with open(sys.stdout.log_file, "r") as f:
        return f.read()


os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1' # å½“é‡åˆ°mpsä¸æ”¯æŒçš„æ­¥éª¤æ—¶ä½¿ç”¨cpu

n_cpu=cpu_count()
           
ngpu = torch.cuda.device_count()
gpu_infos = []
mem = []
if_gpu_ok = False

# åˆ¤æ–­æ˜¯å¦æœ‰èƒ½ç”¨æ¥è®­ç»ƒå’ŒåŠ é€Ÿæ¨ç†çš„Nå¡
if torch.cuda.is_available() or ngpu != 0:
    for i in range(ngpu):
        gpu_name = torch.cuda.get_device_name(i)
        if any(value in gpu_name.upper()for value in ["10","16","20","30","40","A2","A3","A4","P4","A50","500","A60","70","80","90","M4","T4","TITAN","L4","4060"]):
            # A10#A100#V100#A40#P40#M40#K80#A4500
            if_gpu_ok = True  # è‡³å°‘æœ‰ä¸€å¼ èƒ½ç”¨çš„Nå¡
            gpu_infos.append("%s\t%s" % (i, gpu_name))
            mem.append(int(torch.cuda.get_device_properties(i).total_memory/ 1024/ 1024/ 1024+ 0.4))
# åˆ¤æ–­æ˜¯å¦æ”¯æŒmpsåŠ é€Ÿ
if torch.backends.mps.is_available():
    if_gpu_ok = True
    gpu_infos.append("%s\t%s" % ("0", "Apple GPU"))
    mem.append(psutil.virtual_memory().total/ 1024 / 1024 / 1024) # å®æµ‹ä½¿ç”¨ç³»ç»Ÿå†…å­˜ä½œä¸ºæ˜¾å­˜ä¸ä¼šçˆ†æ˜¾å­˜

if if_gpu_ok and len(gpu_infos) > 0:
    gpu_info = "\n".join(gpu_infos)
    default_batch_size = min(mem) // 2
else:
    gpu_info = i18n("å¾ˆé—æ†¾æ‚¨è¿™æ²¡æœ‰èƒ½ç”¨çš„æ˜¾å¡æ¥æ”¯æŒæ‚¨è®­ç»ƒ")
    default_batch_size = 1
gpus = "-".join([i[0] for i in gpu_infos])

pretrained_sovits_name="GPT_SoVITS/pretrained_models/s2G488k.pth"
pretrained_gpt_name="GPT_SoVITS/pretrained_models/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt"
def get_weights_names():
    SoVITS_names = [pretrained_sovits_name]
    for name in os.listdir(SoVITS_weight_root):
        if name.endswith(".pth"):SoVITS_names.append(name)
    GPT_names = [pretrained_gpt_name]
    for name in os.listdir(GPT_weight_root):
        if name.endswith(".ckpt"): GPT_names.append(name)
    return SoVITS_names,GPT_names
SoVITS_weight_root="SoVITS_weights"
GPT_weight_root="GPT_weights"
os.makedirs(SoVITS_weight_root,exist_ok=True)
os.makedirs(GPT_weight_root,exist_ok=True)
SoVITS_names,GPT_names = get_weights_names()

def custom_sort_key(s):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å­—ç¬¦ä¸²ä¸­çš„æ•°å­—éƒ¨åˆ†å’Œéæ•°å­—éƒ¨åˆ†
    parts = re.split('(\d+)', s)
    # å°†æ•°å­—éƒ¨åˆ†è½¬æ¢ä¸ºæ•´æ•°ï¼Œéæ•°å­—éƒ¨åˆ†ä¿æŒä¸å˜
    parts = [int(part) if part.isdigit() else part for part in parts]
    return parts

def change_choices():
    SoVITS_names, GPT_names = get_weights_names()
    return {"choices": sorted(SoVITS_names,key=custom_sort_key), "__type__": "update"}, {"choices": sorted(GPT_names,key=custom_sort_key), "__type__": "update"}

p_label=None
p_uvr5=None
p_asr=None
p_denoise=None
p_tts_inference=None

def kill_proc_tree(pid, including_parent=True):  
    try:
        parent = psutil.Process(pid)
    except psutil.NoSuchProcess:
        # Process already terminated
        return

    children = parent.children(recursive=True)
    for child in children:
        try:
            os.kill(child.pid, signal.SIGTERM)  # or signal.SIGKILL
        except OSError:
            pass
    if including_parent:
        try:
            os.kill(parent.pid, signal.SIGTERM)  # or signal.SIGKILL
        except OSError:
            pass

system=platform.system()
def kill_process(pid):
    if(system=="Windows"):
        cmd = "taskkill /t /f /pid %s" % pid
        os.system(cmd)
    else:
        kill_proc_tree(pid)
    

def change_label(if_label,path_list):
    global p_label
    if(if_label==True and p_label==None):
        path_list=my_utils.clean_path(path_list)
        cmd = '"%s" tools/subfix_webui.py --load_list "%s" --webui_port %s --is_share %s'%(python_exec,path_list,webui_port_subfix,is_share)
        yield i18n("æ‰“æ ‡å·¥å…·WebUIå·²å¼€å¯")
        print(cmd)
        p_label = Popen(cmd, shell=True)
    elif(if_label==False and p_label!=None):
        kill_process(p_label.pid)
        p_label=None
        yield i18n("æ‰“æ ‡å·¥å…·WebUIå·²å…³é—­")

def change_uvr5(if_uvr5):
    global p_uvr5
    if(if_uvr5==True and p_uvr5==None):
        cmd = '"%s" tools/uvr5/webui.py "%s" %s %s %s'%(python_exec,infer_device,is_half,webui_port_uvr5,is_share)
        yield i18n("UVR5å·²å¼€å¯")
        print(cmd)
        p_uvr5 = Popen(cmd, shell=True)
    elif(if_uvr5==False and p_uvr5!=None):
        kill_process(p_uvr5.pid)
        p_uvr5=None
        yield i18n("UVR5å·²å…³é—­")

def change_tts_inference(if_tts,bert_path,cnhubert_base_path,gpu_number,gpt_path,sovits_path):
    global p_tts_inference
    if(if_tts==True and p_tts_inference==None):
        os.environ["gpt_path"]=gpt_path if "/" in gpt_path else "%s/%s"%(GPT_weight_root,gpt_path)
        os.environ["sovits_path"]=sovits_path if "/"in sovits_path else "%s/%s"%(SoVITS_weight_root,sovits_path)
        os.environ["cnhubert_base_path"]=cnhubert_base_path
        os.environ["bert_path"]=bert_path
        os.environ["_CUDA_VISIBLE_DEVICES"]=gpu_number
        os.environ["is_half"]=str(is_half)
        os.environ["infer_ttswebui"]=str(webui_port_infer_tts)
        os.environ["is_share"]=str(is_share)
        cmd = '"%s" GPT_SoVITS/inference_webui.py'%(python_exec)
        yield i18n("TTSæ¨ç†è¿›ç¨‹å·²å¼€å¯")
        print(cmd)
        p_tts_inference = Popen(cmd, shell=True)
    elif(if_tts==False and p_tts_inference!=None):
        kill_process(p_tts_inference.pid)
        p_tts_inference=None
        yield i18n("TTSæ¨ç†è¿›ç¨‹å·²å…³é—­")

from tools.asr.config import asr_dict
def open_asr(asr_inp_dir, asr_opt_dir, asr_model, asr_model_size, asr_lang):
    global p_asr
    if(p_asr==None):
        asr_inp_dir=my_utils.clean_path(asr_inp_dir)
        cmd = f'"{python_exec}" tools/asr/{asr_dict[asr_model]["path"]}'
        cmd += f' -i "{asr_inp_dir}"'
        cmd += f' -o "{asr_opt_dir}"'
        cmd += f' -s {asr_model_size}'
        cmd += f' -l {asr_lang}'
        cmd += " -p %s"%("float16"if is_half==True else "float32")

        yield "ASRä»»åŠ¡å¼€å¯ï¼š%s"%cmd,{"__type__":"update","visible":False},{"__type__":"update","visible":True}
        print(cmd)
        p_asr = Popen(cmd, shell=True)
        p_asr.wait()
        p_asr=None
        yield f"ASRä»»åŠ¡å®Œæˆ, æŸ¥çœ‹ç»ˆç«¯è¿›è¡Œä¸‹ä¸€æ­¥",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„ASRä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡",{"__type__":"update","visible":False},{"__type__":"update","visible":True}
        # return None

def close_asr():
    global p_asr
    if(p_asr!=None):
        kill_process(p_asr.pid)
        p_asr=None
    return "å·²ç»ˆæ­¢ASRè¿›ç¨‹",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
def open_denoise(denoise_inp_dir, denoise_opt_dir):
    global p_denoise
    if(p_denoise==None):
        denoise_inp_dir=my_utils.clean_path(denoise_inp_dir)
        denoise_opt_dir=my_utils.clean_path(denoise_opt_dir)
        cmd = '"%s" tools/cmd-denoise.py -i "%s" -o "%s" -p %s'%(python_exec,denoise_inp_dir,denoise_opt_dir,"float16"if is_half==True else "float32")

        yield "è¯­éŸ³é™å™ªä»»åŠ¡å¼€å¯ï¼š%s"%cmd,{"__type__":"update","visible":False},{"__type__":"update","visible":True}
        print(cmd)
        p_denoise = Popen(cmd, shell=True)
        p_denoise.wait()
        p_denoise=None
        yield f"è¯­éŸ³é™å™ªä»»åŠ¡å®Œæˆ, æŸ¥çœ‹ç»ˆç«¯è¿›è¡Œä¸‹ä¸€æ­¥",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„è¯­éŸ³é™å™ªä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡",{"__type__":"update","visible":False},{"__type__":"update","visible":True}
        # return None

def close_denoise():
    global p_denoise
    if(p_denoise!=None):
        kill_process(p_denoise.pid)
        p_denoise=None
    return "å·²ç»ˆæ­¢è¯­éŸ³é™å™ªè¿›ç¨‹",{"__type__":"update","visible":True},{"__type__":"update","visible":False}

p_train_SoVITS=None
def open1Ba(batch_size,total_epoch,exp_name,text_low_lr_rate,if_save_latest,if_save_every_weights,save_every_epoch,gpu_numbers1Ba,pretrained_s2G,pretrained_s2D):
    global p_train_SoVITS
    if(p_train_SoVITS==None):
        with open("GPT_SoVITS/configs/s2.json")as f:
            data=f.read()
            data=json.loads(data)
        s2_dir="%s/%s"%(exp_root,exp_name)
        os.makedirs("%s/logs_s2"%(s2_dir),exist_ok=True)
        if(is_half==False):
            data["train"]["fp16_run"]=False
            batch_size=max(1,batch_size//2)
        data["train"]["batch_size"]=batch_size
        data["train"]["epochs"]=total_epoch
        data["train"]["text_low_lr_rate"]=text_low_lr_rate
        data["train"]["pretrained_s2G"]=pretrained_s2G
        data["train"]["pretrained_s2D"]=pretrained_s2D
        data["train"]["if_save_latest"]=if_save_latest
        data["train"]["if_save_every_weights"]=if_save_every_weights
        data["train"]["save_every_epoch"]=save_every_epoch
        data["train"]["gpu_numbers"]=gpu_numbers1Ba
        data["data"]["exp_dir"]=data["s2_ckpt_dir"]=s2_dir
        data["save_weight_dir"]=SoVITS_weight_root
        data["name"]=exp_name
        tmp_config_path="%s/tmp_s2.json"%tmp
        with open(tmp_config_path,"w")as f:f.write(json.dumps(data))

        cmd = '"%s" GPT_SoVITS/s2_train.py --config "%s"'%(python_exec,tmp_config_path)
        yield "SoVITSè®­ç»ƒå¼€å§‹ï¼š%s"%cmd,{"__type__":"update","visible":False},{"__type__":"update","visible":True}
        print(cmd)
        p_train_SoVITS = Popen(cmd, shell=True)
        p_train_SoVITS.wait()
        p_train_SoVITS=None
        yield "SoVITSè®­ç»ƒå®Œæˆ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„SoVITSè®­ç»ƒä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡",{"__type__":"update","visible":False},{"__type__":"update","visible":True}

def close1Ba():
    global p_train_SoVITS
    if(p_train_SoVITS!=None):
        kill_process(p_train_SoVITS.pid)
        p_train_SoVITS=None
    return "å·²ç»ˆæ­¢SoVITSè®­ç»ƒ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}

p_train_GPT=None
def open1Bb(batch_size,total_epoch,exp_name,if_dpo,if_save_latest,if_save_every_weights,save_every_epoch,gpu_numbers,pretrained_s1):
    global p_train_GPT
    if(p_train_GPT==None):
        with open("GPT_SoVITS/configs/s1longer.yaml")as f:
            data=f.read()
            data=yaml.load(data, Loader=yaml.FullLoader)
        s1_dir="%s/%s"%(exp_root,exp_name)
        os.makedirs("%s/logs_s1"%(s1_dir),exist_ok=True)
        if(is_half==False):
            data["train"]["precision"]="32"
            batch_size = max(1, batch_size // 2)
        data["train"]["batch_size"]=batch_size
        data["train"]["epochs"]=total_epoch
        data["pretrained_s1"]=pretrained_s1
        data["train"]["save_every_n_epoch"]=save_every_epoch
        data["train"]["if_save_every_weights"]=if_save_every_weights
        data["train"]["if_save_latest"]=if_save_latest
        data["train"]["if_dpo"]=if_dpo
        data["train"]["half_weights_save_dir"]=GPT_weight_root
        data["train"]["exp_name"]=exp_name
        data["train_semantic_path"]="%s/6-name2semantic.tsv"%s1_dir
        data["train_phoneme_path"]="%s/2-name2text.txt"%s1_dir
        data["output_dir"]="%s/logs_s1"%s1_dir

        os.environ["_CUDA_VISIBLE_DEVICES"]=gpu_numbers.replace("-",",")
        os.environ["hz"]="25hz"
        tmp_config_path="%s/tmp_s1.yaml"%tmp
        with open(tmp_config_path, "w") as f:f.write(yaml.dump(data, default_flow_style=False))
        # cmd = '"%s" GPT_SoVITS/s1_train.py --config_file "%s" --train_semantic_path "%s/6-name2semantic.tsv" --train_phoneme_path "%s/2-name2text.txt" --output_dir "%s/logs_s1"'%(python_exec,tmp_config_path,s1_dir,s1_dir,s1_dir)
        cmd = '"%s" GPT_SoVITS/s1_train.py --config_file "%s" '%(python_exec,tmp_config_path)
        yield "GPTè®­ç»ƒå¼€å§‹ï¼š%s"%cmd,{"__type__":"update","visible":False},{"__type__":"update","visible":True}
        print(cmd)
        p_train_GPT = Popen(cmd, shell=True)
        p_train_GPT.wait()
        p_train_GPT=None
        yield "GPTè®­ç»ƒå®Œæˆ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„GPTè®­ç»ƒä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡",{"__type__":"update","visible":False},{"__type__":"update","visible":True}

def close1Bb():
    global p_train_GPT
    if(p_train_GPT!=None):
        kill_process(p_train_GPT.pid)
        p_train_GPT=None
    return "å·²ç»ˆæ­¢GPTè®­ç»ƒ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}

ps_slice=[]
def open_slice(inp,opt_root,threshold,min_length,min_interval,hop_size,max_sil_kept,_max,alpha,n_parts):
    global ps_slice
    inp = my_utils.clean_path(inp)
    opt_root = my_utils.clean_path(opt_root)
    if(os.path.exists(inp)==False):
        yield "è¾“å…¥è·¯å¾„ä¸å­˜åœ¨",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
        return
    if os.path.isfile(inp):n_parts=1
    elif os.path.isdir(inp):pass
    else:
        yield "è¾“å…¥è·¯å¾„å­˜åœ¨ä½†æ—¢ä¸æ˜¯æ–‡ä»¶ä¹Ÿä¸æ˜¯æ–‡ä»¶å¤¹",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
        return
    if (ps_slice == []):
        for i_part in range(n_parts):
            cmd = '"%s" tools/slice_audio.py "%s" "%s" %s %s %s %s %s %s %s %s %s''' % (python_exec,inp, opt_root, threshold, min_length, min_interval, hop_size, max_sil_kept, _max, alpha, i_part, n_parts)
            print(cmd)
            p = Popen(cmd, shell=True)
            ps_slice.append(p)
        yield "åˆ‡å‰²æ‰§è¡Œä¸­", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
        for p in ps_slice:
            p.wait()
        ps_slice=[]
        yield "åˆ‡å‰²ç»“æŸ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„åˆ‡å‰²ä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}

def close_slice():
    global ps_slice
    if (ps_slice != []):
        for p_slice in ps_slice:
            try:
                kill_process(p_slice.pid)
            except:
                traceback.print_exc()
        ps_slice=[]
    return "å·²ç»ˆæ­¢æ‰€æœ‰åˆ‡å‰²è¿›ç¨‹", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}

ps1a=[]
def open1a(inp_text,inp_wav_dir,exp_name,gpu_numbers,bert_pretrained_dir):
    global ps1a
    inp_text = my_utils.clean_path(inp_text)
    inp_wav_dir = my_utils.clean_path(inp_wav_dir)
    if (ps1a == []):
        opt_dir="%s/%s"%(exp_root,exp_name)
        config={
            "inp_text":inp_text,
            "inp_wav_dir":inp_wav_dir,
            "exp_name":exp_name,
            "opt_dir":opt_dir,
            "bert_pretrained_dir":bert_pretrained_dir,
        }
        gpu_names=gpu_numbers.split("-")
        all_parts=len(gpu_names)
        for i_part in range(all_parts):
            config.update(
                {
                    "i_part": str(i_part),
                    "all_parts": str(all_parts),
                    "_CUDA_VISIBLE_DEVICES": gpu_names[i_part],
                    "is_half": str(is_half)
                }
            )
            os.environ.update(config)
            cmd = '"%s" GPT_SoVITS/prepare_datasets/1-get-text.py'%python_exec
            print(cmd)
            p = Popen(cmd, shell=True)
            ps1a.append(p)
        yield "æ–‡æœ¬è¿›ç¨‹æ‰§è¡Œä¸­", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
        for p in ps1a:
            p.wait()
        opt = []
        for i_part in range(all_parts):
            txt_path = "%s/2-name2text-%s.txt" % (opt_dir, i_part)
            with open(txt_path, "r", encoding="utf8") as f:
                opt += f.read().strip("\n").split("\n")
            os.remove(txt_path)
        path_text = "%s/2-name2text.txt" % opt_dir
        with open(path_text, "w", encoding="utf8") as f:
            f.write("\n".join(opt) + "\n")
        ps1a=[]
        yield "æ–‡æœ¬è¿›ç¨‹ç»“æŸ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„æ–‡æœ¬ä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}

def close1a():
    global ps1a
    if (ps1a != []):
        for p1a in ps1a:
            try:
                kill_process(p1a.pid)
            except:
                traceback.print_exc()
        ps1a=[]
    return "å·²ç»ˆæ­¢æ‰€æœ‰1aè¿›ç¨‹", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}

ps1b=[]
def open1b(inp_text,inp_wav_dir,exp_name,gpu_numbers,ssl_pretrained_dir):
    global ps1b
    inp_text = my_utils.clean_path(inp_text)
    inp_wav_dir = my_utils.clean_path(inp_wav_dir)
    if (ps1b == []):
        config={
            "inp_text":inp_text,
            "inp_wav_dir":inp_wav_dir,
            "exp_name":exp_name,
            "opt_dir":"%s/%s"%(exp_root,exp_name),
            "cnhubert_base_dir":ssl_pretrained_dir,
            "is_half": str(is_half)
        }
        gpu_names=gpu_numbers.split("-")
        all_parts=len(gpu_names)
        for i_part in range(all_parts):
            config.update(
                {
                    "i_part": str(i_part),
                    "all_parts": str(all_parts),
                    "_CUDA_VISIBLE_DEVICES": gpu_names[i_part],
                }
            )
            os.environ.update(config)
            cmd = '"%s" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py'%python_exec
            print(cmd)
            p = Popen(cmd, shell=True)
            ps1b.append(p)
        yield "SSLæå–è¿›ç¨‹æ‰§è¡Œä¸­", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
        for p in ps1b:
            p.wait()
        ps1b=[]
        yield "SSLæå–è¿›ç¨‹ç»“æŸ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„SSLæå–ä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}

def close1b():
    global ps1b
    if (ps1b != []):
        for p1b in ps1b:
            try:
                kill_process(p1b.pid)
            except:
                traceback.print_exc()
        ps1b=[]
    return "å·²ç»ˆæ­¢æ‰€æœ‰1bè¿›ç¨‹", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}

ps1c=[]
def open1c(inp_text,exp_name,gpu_numbers,pretrained_s2G_path):
    global ps1c
    inp_text = my_utils.clean_path(inp_text)
    if (ps1c == []):
        opt_dir="%s/%s"%(exp_root,exp_name)
        config={
            "inp_text":inp_text,
            "exp_name":exp_name,
            "opt_dir":opt_dir,
            "pretrained_s2G":pretrained_s2G_path,
            "s2config_path":"GPT_SoVITS/configs/s2.json",
            "is_half": str(is_half)
        }
        gpu_names=gpu_numbers.split("-")
        all_parts=len(gpu_names)
        for i_part in range(all_parts):
            config.update(
                {
                    "i_part": str(i_part),
                    "all_parts": str(all_parts),
                    "_CUDA_VISIBLE_DEVICES": gpu_names[i_part],
                }
            )
            os.environ.update(config)
            cmd = '"%s" GPT_SoVITS/prepare_datasets/3-get-semantic.py'%python_exec
            print(cmd)
            p = Popen(cmd, shell=True)
            ps1c.append(p)
        yield "è¯­ä¹‰tokenæå–è¿›ç¨‹æ‰§è¡Œä¸­", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
        for p in ps1c:
            p.wait()
        opt = ["item_name\tsemantic_audio"]
        path_semantic = "%s/6-name2semantic.tsv" % opt_dir
        for i_part in range(all_parts):
            semantic_path = "%s/6-name2semantic-%s.tsv" % (opt_dir, i_part)
            with open(semantic_path, "r", encoding="utf8") as f:
                opt += f.read().strip("\n").split("\n")
            os.remove(semantic_path)
        with open(path_semantic, "w", encoding="utf8") as f:
            f.write("\n".join(opt) + "\n")
        ps1c=[]
        yield "è¯­ä¹‰tokenæå–è¿›ç¨‹ç»“æŸ",{"__type__":"update","visible":True},{"__type__":"update","visible":False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„è¯­ä¹‰tokenæå–ä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}

def close1c():
    global ps1c
    if (ps1c != []):
        for p1c in ps1c:
            try:
                kill_process(p1c.pid)
            except:
                traceback.print_exc()
        ps1c=[]
    return "å·²ç»ˆæ­¢æ‰€æœ‰è¯­ä¹‰tokenè¿›ç¨‹", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}
#####inp_text,inp_wav_dir,exp_name,gpu_numbers1a,gpu_numbers1Ba,gpu_numbers1c,bert_pretrained_dir,cnhubert_base_dir,pretrained_s2G
ps1abc=[]
def open1abc(inp_text,inp_wav_dir,exp_name,gpu_numbers1a,gpu_numbers1Ba,gpu_numbers1c,bert_pretrained_dir,ssl_pretrained_dir,pretrained_s2G_path):
    global ps1abc
    inp_text = my_utils.clean_path(inp_text)
    inp_wav_dir = my_utils.clean_path(inp_wav_dir)
    if (ps1abc == []):
        opt_dir="%s/%s"%(exp_root,exp_name)
        try:
            #############################1a
            path_text="%s/2-name2text.txt" % opt_dir
            if(os.path.exists(path_text)==False or (os.path.exists(path_text)==True and len(open(path_text,"r",encoding="utf8").read().strip("\n").split("\n"))<2)):
                config={
                    "inp_text":inp_text,
                    "inp_wav_dir":inp_wav_dir,
                    "exp_name":exp_name,
                    "opt_dir":opt_dir,
                    "bert_pretrained_dir":bert_pretrained_dir,
                    "is_half": str(is_half)
                }
                gpu_names=gpu_numbers1a.split("-")
                all_parts=len(gpu_names)
                for i_part in range(all_parts):
                    config.update(
                        {
                            "i_part": str(i_part),
                            "all_parts": str(all_parts),
                            "_CUDA_VISIBLE_DEVICES": gpu_names[i_part],
                        }
                    )
                    os.environ.update(config)
                    cmd = '"%s" GPT_SoVITS/prepare_datasets/1-get-text.py'%python_exec
                    print(cmd)
                    p = Popen(cmd, shell=True)
                    ps1abc.append(p)
                yield "è¿›åº¦ï¼š1a-ing", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
                for p in ps1abc:p.wait()

                opt = []
                for i_part in range(all_parts):#txt_path="%s/2-name2text-%s.txt"%(opt_dir,i_part)
                    txt_path = "%s/2-name2text-%s.txt" % (opt_dir, i_part)
                    with open(txt_path, "r",encoding="utf8") as f:
                        opt += f.read().strip("\n").split("\n")
                    os.remove(txt_path)
                with open(path_text, "w",encoding="utf8") as f:
                    f.write("\n".join(opt) + "\n")

            yield "è¿›åº¦ï¼š1a-done", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
            ps1abc=[]
            #############################1b
            config={
                "inp_text":inp_text,
                "inp_wav_dir":inp_wav_dir,
                "exp_name":exp_name,
                "opt_dir":opt_dir,
                "cnhubert_base_dir":ssl_pretrained_dir,
            }
            gpu_names=gpu_numbers1Ba.split("-")
            all_parts=len(gpu_names)
            for i_part in range(all_parts):
                config.update(
                    {
                        "i_part": str(i_part),
                        "all_parts": str(all_parts),
                        "_CUDA_VISIBLE_DEVICES": gpu_names[i_part],
                    }
                )
                os.environ.update(config)
                cmd = '"%s" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py'%python_exec
                print(cmd)
                p = Popen(cmd, shell=True)
                ps1abc.append(p)
            yield "è¿›åº¦ï¼š1a-done, 1b-ing", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
            for p in ps1abc:p.wait()
            yield "è¿›åº¦ï¼š1a1b-done", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
            ps1abc=[]
            #############################1c
            path_semantic = "%s/6-name2semantic.tsv" % opt_dir
            if(os.path.exists(path_semantic)==False or (os.path.exists(path_semantic)==True and os.path.getsize(path_semantic)<31)):
                config={
                    "inp_text":inp_text,
                    "exp_name":exp_name,
                    "opt_dir":opt_dir,
                    "pretrained_s2G":pretrained_s2G_path,
                    "s2config_path":"GPT_SoVITS/configs/s2.json",
                }
                gpu_names=gpu_numbers1c.split("-")
                all_parts=len(gpu_names)
                for i_part in range(all_parts):
                    config.update(
                        {
                            "i_part": str(i_part),
                            "all_parts": str(all_parts),
                            "_CUDA_VISIBLE_DEVICES": gpu_names[i_part],
                        }
                    )
                    os.environ.update(config)
                    cmd = '"%s" GPT_SoVITS/prepare_datasets/3-get-semantic.py'%python_exec
                    print(cmd)
                    p = Popen(cmd, shell=True)
                    ps1abc.append(p)
                yield "è¿›åº¦ï¼š1a1b-done, 1cing", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
                for p in ps1abc:p.wait()

                opt = ["item_name\tsemantic_audio"]
                for i_part in range(all_parts):
                    semantic_path = "%s/6-name2semantic-%s.tsv" % (opt_dir, i_part)
                    with open(semantic_path, "r",encoding="utf8") as f:
                        opt += f.read().strip("\n").split("\n")
                    os.remove(semantic_path)
                with open(path_semantic, "w",encoding="utf8") as f:
                    f.write("\n".join(opt) + "\n")
                yield "è¿›åº¦ï¼šall-done", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}
            ps1abc = []
            yield "ä¸€é”®ä¸‰è¿è¿›ç¨‹ç»“æŸ", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}
        except:
            traceback.print_exc()
            close1abc()
            yield "ä¸€é”®ä¸‰è¿ä¸­é€”æŠ¥é”™", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}
    else:
        yield "å·²æœ‰æ­£åœ¨è¿›è¡Œçš„ä¸€é”®ä¸‰è¿ä»»åŠ¡ï¼Œéœ€å…ˆç»ˆæ­¢æ‰èƒ½å¼€å¯ä¸‹ä¸€æ¬¡ä»»åŠ¡", {"__type__": "update", "visible": False}, {"__type__": "update", "visible": True}

def close1abc():
    global ps1abc
    if (ps1abc != []):
        for p1abc in ps1abc:
            try:
                kill_process(p1abc.pid)
            except:
                traceback.print_exc()
        ps1abc=[]
    return "å·²ç»ˆæ­¢æ‰€æœ‰ä¸€é”®ä¸‰è¿è¿›ç¨‹", {"__type__": "update", "visible": True}, {"__type__": "update", "visible": False}

with gr.Blocks(title="GPT-SoVITS WebUI") as app:
    gr.Markdown("# <center>ğŸŒŠğŸ’•ğŸ¶ XTTS å¾®è°ƒï¼š2åˆ†é’Ÿè¯­éŸ³ï¼Œå¼€å¯ä¸­æ—¥è‹±16ç§è¯­è¨€çœŸå®æ‹Ÿå£°</center>")
    gr.Markdown("## <center>ğŸŒŸ åªéœ€2åˆ†é’Ÿçš„è¯­éŸ³ï¼Œä¸€é”®åœ¨çº¿å¾®è°ƒ æœ€å¼ºå¤šè¯­ç§æ¨¡å‹</center>")
    gr.Markdown("### <center>ğŸ¤— æ›´å¤šç²¾å½©ï¼Œå°½åœ¨[æ»”æ»”AI](https://www.talktalkai.com/)ï¼›æ»”æ»”AIï¼Œä¸ºçˆ±æ»”æ»”ï¼ğŸ’•</center>")

    with gr.Tabs():
        with gr.TabItem(i18n("1 - åˆ¶ä½œæ•°æ®é›†")):#æå‰éšæœºåˆ‡ç‰‡é˜²æ­¢uvr5çˆ†å†…å­˜->uvr5->slicer->asr->æ‰“æ ‡
            #gr.Markdown(value=i18n("0a-UVR5äººå£°ä¼´å¥åˆ†ç¦»&å»æ··å“å»å»¶è¿Ÿå·¥å…·"))
            with gr.Row():
                if_uvr5 = gr.Checkbox(label=i18n("æ˜¯å¦å¼€å¯UVR5-WebUI"),show_label=True, visible=False)
                uvr5_info = gr.Textbox(label=i18n("UVR5è¿›ç¨‹è¾“å‡ºä¿¡æ¯"), visible=False)
            gr.Markdown(value=i18n("1a-è¯­éŸ³åˆ‡åˆ†å·¥å…·"))
            with gr.Row():
                with gr.Row():
                    slice_inp_path=gr.Textbox(label=i18n("éŸ³é¢‘è‡ªåŠ¨åˆ‡åˆ†è¾“å…¥è·¯å¾„ï¼Œå¯æ–‡ä»¶å¯æ–‡ä»¶å¤¹"),info="æ‚¨éœ€è¦å…ˆåœ¨xtts-v2æ–‡ä»¶å¤¹ä¸­ä¸Šä¼ è®­ç»ƒéŸ³é¢‘ï¼Œå¦‚jay.wavï¼›éŸ³é¢‘æ—¶é•¿å»ºè®®å¤§äº2åˆ†é’Ÿ",value="",placeholder="jay.wav")
                    slice_opt_root=gr.Textbox(label=i18n("åˆ‡åˆ†åçš„å­éŸ³é¢‘çš„è¾“å‡ºæ ¹ç›®å½•"),value="output/slicer_opt")
                    threshold=gr.Textbox(label=i18n("threshold:éŸ³é‡å°äºè¿™ä¸ªå€¼è§†ä½œé™éŸ³çš„å¤‡é€‰åˆ‡å‰²ç‚¹"),value="-34")
                    min_length=gr.Textbox(label=i18n("min_length:æ¯æ®µæœ€å°å¤šé•¿ï¼Œå¦‚æœç¬¬ä¸€æ®µå¤ªçŸ­ä¸€ç›´å’Œåé¢æ®µè¿èµ·æ¥ç›´åˆ°è¶…è¿‡è¿™ä¸ªå€¼"),value="4000")
                    min_interval=gr.Textbox(label=i18n("min_interval:æœ€çŸ­åˆ‡å‰²é—´éš”"),value="300")
                    hop_size=gr.Textbox(label=i18n("hop_size:æ€ä¹ˆç®—éŸ³é‡æ›²çº¿ï¼Œè¶Šå°ç²¾åº¦è¶Šå¤§è®¡ç®—é‡è¶Šé«˜ï¼ˆä¸æ˜¯ç²¾åº¦è¶Šå¤§æ•ˆæœè¶Šå¥½ï¼‰"),value="10")
                    max_sil_kept=gr.Textbox(label=i18n("max_sil_kept:åˆ‡å®Œåé™éŸ³æœ€å¤šç•™å¤šé•¿"),value="500")
                with gr.Row():
                    open_slicer_button=gr.Button(i18n("1. å¼€å¯è¯­éŸ³åˆ‡å‰²"), variant="primary",visible=True)
                    close_slicer_button=gr.Button(i18n("ç»ˆæ­¢è¯­éŸ³åˆ‡å‰²"), variant="primary",visible=False)
                    _max=gr.Slider(minimum=0,maximum=1,step=0.05,label=i18n("max:å½’ä¸€åŒ–åæœ€å¤§å€¼å¤šå°‘"),value=0.9,interactive=True)
                    alpha=gr.Slider(minimum=0,maximum=1,step=0.05,label=i18n("alpha_mix:æ··å¤šå°‘æ¯”ä¾‹å½’ä¸€åŒ–åéŸ³é¢‘è¿›æ¥"),value=0.25,interactive=True)
                    n_process=gr.Slider(minimum=1,maximum=n_cpu,step=1,label=i18n("åˆ‡å‰²ä½¿ç”¨çš„è¿›ç¨‹æ•°"),value=4,interactive=True)
                    slicer_info = gr.Textbox(label=i18n("è¯­éŸ³åˆ‡å‰²è¿›ç¨‹è¾“å‡ºä¿¡æ¯"))
            #gr.Markdown(value=i18n("0bb-è¯­éŸ³é™å™ªå·¥å…·"))
            with gr.Row():
                open_denoise_button = gr.Button(i18n("å¼€å¯è¯­éŸ³é™å™ª"), visible=False)
                close_denoise_button = gr.Button(i18n("ç»ˆæ­¢è¯­éŸ³é™å™ªè¿›ç¨‹"), variant="primary",visible=False)
                denoise_input_dir=gr.Textbox(label=i18n("é™å™ªéŸ³é¢‘æ–‡ä»¶è¾“å…¥æ–‡ä»¶å¤¹"),value="", visible=False)
                denoise_output_dir=gr.Textbox(label=i18n("é™å™ªç»“æœè¾“å‡ºæ–‡ä»¶å¤¹"),value="output/denoise_opt", visible=False)
                denoise_info = gr.Textbox(label=i18n("è¯­éŸ³é™å™ªè¿›ç¨‹è¾“å‡ºä¿¡æ¯"), visible=False)
            gr.Markdown(value=i18n("1b-æ‰¹é‡è¯­éŸ³è¯†åˆ«"))
            with gr.Row():
                open_asr_button = gr.Button(i18n("2. å¼€å¯ç¦»çº¿æ‰¹é‡ASR"), variant="primary",visible=True)
                close_asr_button = gr.Button(i18n("ç»ˆæ­¢ASRè¿›ç¨‹"), variant="primary",visible=False)
                with gr.Column():
                    with gr.Row():
                        asr_inp_dir = gr.Textbox(
                            label=i18n("è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„"),
                            value="output/slicer_opt",
                            interactive=True,
                        )
                        asr_opt_dir = gr.Textbox(
                            label       = i18n("è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„"),
                            value       = "output/asr_opt",
                            interactive = True,
                        )
                    with gr.Row():
                        asr_model = gr.Dropdown(
                            label       = i18n("ASR æ¨¡å‹"),
                            choices     = list(asr_dict.keys()),
                            interactive = True,
                            value="è¾¾æ‘© ASR (ä¸­æ–‡)"
                        )
                        asr_size = gr.Dropdown(
                            label       = i18n("ASR æ¨¡å‹å°ºå¯¸"),
                            choices     = ["large"],
                            interactive = True,
                            value="large"
                        )
                        asr_lang = gr.Dropdown(
                            label       = i18n("ASR è¯­è¨€è®¾ç½®"),
                            choices     = ["zh"],
                            interactive = True,
                            value="zh"
                        )
                        lang = asr_lang
                    with gr.Row():
                        asr_info = gr.Textbox(label=i18n("ASRè¿›ç¨‹è¾“å‡ºä¿¡æ¯"))

                def change_lang_choices(key): #æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ä¿®æ”¹å¯é€‰çš„è¯­è¨€
                    # return gr.Dropdown(choices=asr_dict[key]['lang'])
                    return {"__type__": "update", "choices": asr_dict[key]['lang'],"value":asr_dict[key]['lang'][0]}
                def change_size_choices(key): # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ä¿®æ”¹å¯é€‰çš„æ¨¡å‹å°ºå¯¸
                    # return gr.Dropdown(choices=asr_dict[key]['size'])
                    return {"__type__": "update", "choices": asr_dict[key]['size']}
                asr_model.change(change_lang_choices, [asr_model], [asr_lang])
                asr_model.change(change_size_choices, [asr_model], [asr_size])
                
            gr.Markdown(value=i18n("1c-è¯­éŸ³æ–‡æœ¬æ ¡å¯¹æ ‡æ³¨å·¥å…·"))
            with gr.Row():
                if_label = gr.Checkbox(label=i18n("æ˜¯å¦å¼€å¯æ‰“æ ‡WebUI"),show_label=True)
                path_list = gr.Textbox(
                    label=i18n(".listæ ‡æ³¨æ–‡ä»¶çš„è·¯å¾„"),
                    value="output/asr_opt/slicer_opt.list",
                    interactive=True,
                )
                label_info = gr.Textbox(label=i18n("æ‰“æ ‡å·¥å…·è¿›ç¨‹è¾“å‡ºä¿¡æ¯"))
            if_label.change(change_label, [if_label,path_list], [label_info])
            if_uvr5.change(change_uvr5, [if_uvr5], [uvr5_info])
            open_asr_button.click(open_asr, [asr_inp_dir, asr_opt_dir, asr_model, asr_size, asr_lang], [asr_info,open_asr_button,close_asr_button])
            close_asr_button.click(close_asr, [], [asr_info,open_asr_button,close_asr_button])
            open_slicer_button.click(open_slice, [slice_inp_path,slice_opt_root,threshold,min_length,min_interval,hop_size,max_sil_kept,_max,alpha,n_process], [slicer_info,open_slicer_button,close_slicer_button])
            close_slicer_button.click(close_slice, [], [slicer_info,open_slicer_button,close_slicer_button])
            open_denoise_button.click(open_denoise, [denoise_input_dir,denoise_output_dir], [denoise_info,open_denoise_button,close_denoise_button])
            close_denoise_button.click(close_denoise, [], [denoise_info,open_denoise_button,close_denoise_button])

        with gr.Tab("2 - XTTSæ¨¡å‹å¾®è°ƒ"):
            inp_list_path_value = str(Path.cwd() / "output/asr_opt/slicer_opt.list")
            out_csv_path_value = str(Path.cwd() / "output.csv")
            inp_list_path = gr.Textbox(value=inp_list_path_value, label=".listæ–‡ä»¶åœ°å€")
            out_csv_path = gr.Textbox(value=out_csv_path_value, label=".csvæ–‡ä»¶åœ°å€")
            list_to_csv = gr.Button("3. å‡†å¤‡è®­ç»ƒcsvæ–‡ä»¶", variant="primary")
            train_csv = gr.Textbox(
                label="è®­ç»ƒæ•°æ®é›†csvæ–‡ä»¶",
            )
            eval_csv = gr.Textbox(
                label="è¯„ä»·æ•°æ®é›†csvæ–‡ä»¶",
            )
            list_to_csv.click(convert_list_to_csv, [inp_list_path, out_csv_path], [train_csv, eval_csv])
            out_path_value = str(Path.cwd() / "finetune_models")
            out_path = gr.Textbox(value=out_path_value, label="XTTSå¾®è°ƒæ¨¡å‹çš„æ–‡ä»¶å¤¹")
            num_epochs =  gr.Slider(
                label="è®­ç»ƒæ­¥æ•° Number of epochs:",
                minimum=1,
                maximum=100,
                step=1,
                value=6,
            )
            batch_size = gr.Slider(
                label="Batch size:",
                minimum=2,
                maximum=512,
                step=1,
                value=2,
            )
            grad_acumm = gr.Slider(
                label="Grad accumulation steps:",
                minimum=1,
                maximum=128,
                step=1,
                value=1,
            )
            max_audio_length = gr.Slider(
                label="Max permitted audio size in seconds:",
                minimum=2,
                maximum=20,
                step=1,
                value=11,
                visible=False,
            )
            progress_train = gr.Label(
                label="è®­ç»ƒè¿›ç¨‹"
            )
            logs_tts_train = gr.Textbox(
                label="è®­ç»ƒè¯¦ç»†ä¿¡æ¯",
                interactive=False,
            )
            app.load(read_logs, None, logs_tts_train, every=1)
            train_btn = gr.Button(value="4. å¼€å§‹æ¨¡å‹è®­ç»ƒ", variant="primary")

            def train_model(language, train_csv, eval_csv, num_epochs, batch_size, grad_acumm, output_path, max_audio_length):
                clear_gpu_cache()
                if not train_csv or not eval_csv:
                    return "You need to run the data processing step or manually set `Train CSV` and `Eval CSV` fields !", "", "", "", ""
                try:
                    # convert seconds to waveform frames
                    max_audio_length = int(max_audio_length * 22050)
                    config_path, original_xtts_checkpoint, vocab_file, exp_path, speaker_wav = train_gpt(language, num_epochs, batch_size, grad_acumm, train_csv, eval_csv, output_path=output_path, max_audio_length=max_audio_length)
                except:
                    traceback.print_exc()
                    error = traceback.format_exc()
                    return f"The training was interrupted due an error !! Please check the console to check the full error message! \n Error summary: {error}", "", "", "", ""

                # copy original files to avoid parameters changes issues
                os.system(f"cp {config_path} {exp_path}")
                os.system(f"cp {vocab_file} {exp_path}")

                ft_xtts_checkpoint = os.path.join(exp_path, "best_model.pth")
                print("Model training done!")
                clear_gpu_cache()
                return "Model training done!", config_path, vocab_file, ft_xtts_checkpoint, speaker_wav

        with gr.Tab("3 - XTTSè¯­éŸ³åˆæˆ"):
            with gr.Row():
                with gr.Column() as col1:
                    xtts_checkpoint = gr.Textbox(
                        label="XTTS checkpoint è·¯å¾„",
                        value="",
                    )
                    xtts_config = gr.Textbox(
                        label="XTTS config è·¯å¾„",
                        value="",
                    )

                    xtts_vocab = gr.Textbox(
                        label="XTTS vocab è·¯å¾„",
                        value="",
                    )
                    progress_load = gr.Label(
                        label="æ¨¡å‹åŠ è½½è¿›ç¨‹"
                    )
                    load_btn = gr.Button(value="5. åŠ è½½å·²è®­ç»ƒå¥½çš„æ¨¡å‹", variant="primary")

                with gr.Column() as col2:
                    ref_audio_names = os.listdir("output/slicer_opt")
                    ref_audio_list = [os.path.join("output/slicer_opt", ref_audio_name) for ref_audio_name in ref_audio_names]
                    speaker_reference_audio = gr.Dropdown(
                        label="è¯·é€‰æ‹©ä¸€æ¡å‚è€ƒéŸ³é¢‘",
                        info="ä¸åŒå‚è€ƒéŸ³é¢‘å¯¹åº”çš„åˆæˆæ•ˆæœä¸åŒï¼Œæ‚¨å¯ä»¥å¤šæ¬¡å°è¯•",
                        value=ref_audio_list[0],
                        choices = ref_audio_list
                    )
                    tts_language = gr.Dropdown(
                        label="è¯­éŸ³åˆæˆçš„è¯­è¨€",
                        value="zh",
                        choices=[
                            "en",
                            "es",
                            "fr",
                            "de",
                            "it",
                            "pt",
                            "pl",
                            "tr",
                            "ru",
                            "nl",
                            "cs",
                            "ar",
                            "zh",
                            "hu",
                            "ko",
                            "ja",
                        ]
                    )

                    tts_text = gr.Textbox(
                        label="è¯·å¡«å†™è¯­éŸ³åˆæˆçš„æ–‡æœ¬.",
                        placeholder="æƒ³è¯´å´è¿˜æ²¡è¯´çš„ï¼Œè¿˜å¾ˆå¤š",
                    )
                    tts_btn = gr.Button(value="6. å¼€å¯AIè¯­éŸ³ä¹‹æ—…å§ğŸ’•", variant="primary")

                with gr.Column() as col3:
                    progress_gen = gr.Label(
                        label="è¯­éŸ³åˆæˆè¿›ç¨‹"
                    )
                    tts_output_audio = gr.Audio(label="ä¸ºæ‚¨åˆæˆçš„ä¸“å±éŸ³é¢‘.")
                    reference_audio = gr.Audio(label="æ‚¨ä½¿ç”¨çš„å‚è€ƒéŸ³é¢‘")

            train_btn.click(
                fn=train_model,
                inputs=[
                    lang,
                    train_csv,
                    eval_csv,
                    num_epochs,
                    batch_size,
                    grad_acumm,
                    out_path,
                    max_audio_length,
                ],
                outputs=[progress_train, xtts_config, xtts_vocab, xtts_checkpoint, speaker_reference_audio],
            )
            
            load_btn.click(
                fn=load_model,
                inputs=[
                    xtts_checkpoint,
                    xtts_config,
                    xtts_vocab
                ],
                outputs=[progress_load],
            )

            tts_btn.click(
                fn=run_tts,
                inputs=[
                    tts_language,
                    tts_text,
                    speaker_reference_audio,
                ],
                outputs=[progress_gen, tts_output_audio, reference_audio],
            )

    gr.Markdown("### <center>æ³¨æ„â—ï¼šè¯·ä¸è¦ç”Ÿæˆä¼šå¯¹ä¸ªäººä»¥åŠç»„ç»‡é€ æˆä¾µå®³çš„å†…å®¹ï¼Œæ­¤ç¨‹åºä»…ä¾›ç§‘ç ”ã€å­¦ä¹ åŠä¸ªäººå¨±ä¹ä½¿ç”¨ã€‚è¯·è‡ªè§‰åˆè§„ä½¿ç”¨æ­¤ç¨‹åºï¼Œç¨‹åºå¼€å‘è€…ä¸è´Ÿæœ‰ä»»ä½•è´£ä»»ã€‚</center>")
    gr.HTML('''
        <div class="footer">
                    <p>ğŸŒŠğŸï¸ğŸ¶ - æ±Ÿæ°´ä¸œæµæ€¥ï¼Œæ»”æ»”æ— å°½å£°ã€‚ æ˜Â·é¡¾ç’˜
                    </p>
        </div>
    ''')
    app.queue().launch(
        share=True,
        show_error=True,
    )
